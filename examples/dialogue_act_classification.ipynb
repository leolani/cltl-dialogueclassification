{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343ee3da-1ffe-40ed-8e1a-8f42ee648d90",
   "metadata": {},
   "source": [
    "# Dialogue Act Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d9751-92f2-4938-8cfd-5d7799eaaffc",
   "metadata": {},
   "source": [
    "This notebook demonstrates how you can use an XLM-RoBERTa classifier finetuned with the MIDAS data set. For this we need to the\n",
    "```cltl.dialogue_act_classification``` package. We will demonstrate how you can apply the classifier to a sequence of utterances in a list but also how you can annotate a dialogue in EMISSOR format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c05197-74e8-4479-b9b4-bb46054a53f5",
   "metadata": {},
   "source": [
    "The model needs to placed in a folder on your local machine. It can be downloaded from:\n",
    "\n",
    "```https://vu.data.surfsara.nl/index.php/s/dw0YCJAVFM870DT```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3bae409-1f7c-4106-bf07-3b33a7fbf806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Path to the local copy of midas-da-xlmroberta model, adapt the path to your local configuration\n",
    "model_path = \"../resources/midas-da-xlmroberta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7e1bb-2e37-4b5e-8586-ce2dc938386b",
   "metadata": {},
   "source": [
    "## Using the classifier on a list of utterances in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc4dd3f-5b1d-417b-9562-0ca47ca5ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cltl.dialogue_act_classification.midas_classifier import MidasDialogTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6e9aa7b-ebf2-4598-b13f-fe9e90b455a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /Users/piek/Desktop/d-Leolani/leolani-models/dialogue_models/midas-da-xlmroberta and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love cats [DialogueAct(type='MIDAS', value='LABEL_4', confidence=0.06285823881626129)]\n",
      "Do you love cats? [DialogueAct(type='MIDAS', value='LABEL_14', confidence=0.05728799104690552)]\n",
      "Yes, I do [DialogueAct(type='MIDAS', value='LABEL_2', confidence=0.05970270186662674)]\n",
      "Do you love cats? [DialogueAct(type='MIDAS', value='LABEL_14', confidence=0.060422565788030624)]\n",
      "No, dogs [DialogueAct(type='MIDAS', value='LABEL_1', confidence=0.06130174919962883)]\n",
      "Ik ben dol op katten [DialogueAct(type='MIDAS', value='LABEL_21', confidence=0.06320066004991531)]\n",
      "Hou jij van katten? [DialogueAct(type='MIDAS', value='LABEL_13', confidence=0.05624299868941307)]\n",
      "Ja, ik ben dol op ze [DialogueAct(type='MIDAS', value='LABEL_13', confidence=0.05842715501785278)]\n",
      "Hou jij van katten? [DialogueAct(type='MIDAS', value='LABEL_15', confidence=0.05861100181937218)]\n",
      "Nee, honden [DialogueAct(type='MIDAS', value='LABEL_13', confidence=0.06360748410224915)]\n"
     ]
    }
   ],
   "source": [
    "sentences_en = [\"I love cats\", \"Do you love cats?\",\"Yes, I do\", \"Do you love cats?\", \"No, dogs\"]\n",
    "sentences_nl = [\"Ik ben dol op katten\", \"Hou jij van katten?\",\"Ja, ik ben dol op ze\", \"Hou jij van katten?\", \"Nee, honden\"]\n",
    "model_path = \"/Users/piek/Desktop/d-Leolani/leolani-models/dialogue_models/midas-da-xlmroberta\"\n",
    "analyzer = MidasDialogTagger(model_path=model_path)\n",
    "for sentence in sentences_en+sentences_nl:\n",
    "    response = analyzer.extract_dialogue_act(sentence)\n",
    "    print(sentence, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69538c8b-e1ca-49d6-8a93-030db46fc1a3",
   "metadata": {},
   "source": [
    "## Annotating conversations in EMISSOR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5174ce76-fdec-44ef-82b8-562609707c27",
   "metadata": {},
   "source": [
    "If a conversation is saved in EMISSOR format, you can use the emissor module to load the conversation and add the dialogue act output of the classifier to the EMISSOR representation. EMISSOR a simple JSON format that is a generated by conversational agents created with the Leolani platform. \n",
    "\n",
    "Reference:\n",
    "\n",
    "```Santamaría, Selene Báez, Thomas Baier, Taewoon Kim, Lea Krause, Jaap Kruijt, and Piek Vossen. \"EMISSOR: A platform for capturing multimodal interactions as Episodic Memories and Interpretations with Situated Scenario-based Ontological References.\" In Proceedings of the 1st Workshop on Multimodal Semantic Representations (MMSR), pp. 56-77. 2021.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e178ddf7-45fd-4394-aee2-23738f1a533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emissor.persistence import ScenarioStorage\n",
    "from emissor.representation.scenario import Modality, Signal\n",
    "from cltl.dialogue_act_classification.add_dialogue_acts_to_emissor import DialogueActAnnotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e10c65a9-cbef-4c3a-9f85-92f829e2a9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /Users/piek/Desktop/test/diaclassification/resources/midas-da-xlmroberta and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# label used to store the provenance of the annotation\n",
    "model_name = \"midas-da-xlmroberta\"\n",
    "annotator = DialogueActAnnotator(model_path=model_path, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6514e542-8e85-49c3-ba09-0c43a824d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Path where the different scenarios are kept, each following the EMISSOR structure\n",
    "path_to_emissor = \"../data/emissor\"\n",
    "### A subfolder within the emissor folder that represents a single scenario\n",
    "scenario = \"14a1c27d-dfd2-465b-9ab2-90e9ea91d214\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e8b3be-137d-4b90-afb0-7a395e64629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_storage = ScenarioStorage(path_to_emissor)\n",
    "scenario_ctrl = scenario_storage.load_scenario(scenario)\n",
    "signals = scenario_ctrl.get_signals(Modality.TEXT)\n",
    "for signal in signals:\n",
    "    ### If there are old annotations, these can be removed using the next call, check the JSON to see what label was used\n",
    "    ### annotator.remove_annotations(signal,[\"MIDAS\", \"python-source:cltl.dialogue_act_classification.midas_classifier\"])\n",
    "    annotator.process_signal(scenario=scenario_ctrl, signal=signal)\n",
    "#### Save the modified scenario to emissor\n",
    "scenario_storage.save_scenario(scenario_ctrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606b9603-70d1-4d13-8348-214147d5cbcb",
   "metadata": {},
   "source": [
    "## End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc5505e-c222-462d-a6fb-3284959a7656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
